{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6336c898",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "1. Parallel Programming in Python\n",
    "2. Multi-threading (shared memory parallelism)\n",
    "3. Multiprocessing (Distributed-memory parallelism)\n",
    "    * Process Class\n",
    "    * Pool Class\n",
    "        * Synchronous calls\n",
    "            * pool.Apply()\n",
    "            * pool.Map()\n",
    "            * pool.Starmap()\n",
    "        * Asynchronous calls\n",
    "            * pool.Apply_async()\n",
    "            * pool.Map_async()\n",
    "            * pool.Starmap_async()\n",
    "            * pool.imap()\n",
    "            * pool.imap_unordered()\n",
    "    * Process-to-Process communication\n",
    "        * Pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9e63a-625c-4baa-97b7-9b58bb1fd2f1",
   "metadata": {},
   "source": [
    "# __Parallel Programming in Python__\n",
    "\n",
    "* It is a type of computation in which many calculations or the execution of processes are carried out simultaneously. \n",
    "* Large problems can be divided into smaller ones, which can then be solved at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f1f03",
   "metadata": {},
   "source": [
    "![Parallel execution of task](images/parallelism.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9bc2ec",
   "metadata": {},
   "source": [
    "Similarly, in python code is executed sequentially\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3370a793-370c-4037-b500-329de6bf919b",
   "metadata": {},
   "source": [
    "**The standard Python library has two main modules for parallel computing:**\n",
    "* Threading\n",
    "* Multiprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87ce3a-d0c4-4267-b63f-be208282fc80",
   "metadata": {},
   "source": [
    "**Before we go to the threading module let us understand what a thread and process is:**\n",
    "* *Thread* : is a thread of execution in a program. Aka, lightweight process.\n",
    "* *Process* : is an instance of a computer program that is being executed.\n",
    "- Thread share the memory and state of the parent, process share nothing.\n",
    "- Process use inter-process communication to communicate, thread do not"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e7cff6c-a6d7-4e92-8940-a306e721a2c3",
   "metadata": {},
   "source": [
    "# __Multi-threading (shared memory parallelism)__ \n",
    "\n",
    "Multithreading is a programming concept and technique that allows a single process to have multiple threads of execution running concurrently within the same program. \n",
    "In simpler terms, it enables a program to perform multiple tasks simultaneously, dividing its workload into smaller units called threads\n",
    "\n",
    "* Good for I/O bound tasks\n",
    "* Subject to the Global Interpreter Lock (GIL)\n",
    "  \n",
    "__In python multi-threading is facilitated by the *threading* module__\n",
    "\n",
    "let's take a look at a simple execution of the threading module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70d008e-a62b-449c-a01a-d6a5811bf1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  0\n",
      "count =  1\n",
      "count =  2\n",
      "count =  3\n",
      "count =  4\n",
      "count =  5\n",
      "count =  6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m             count \u001b[39m=\u001b[39m i\n\u001b[1;32m     13\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcount = \u001b[39m\u001b[39m\"\u001b[39m, count)\n\u001b[0;32m---> 15\u001b[0m worker(inp_list, count)\n\u001b[1;32m     17\u001b[0m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhit enter to exit loop\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m complete \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inp_list, count)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m complete:\n\u001b[1;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m inp_list:\n\u001b[0;32m---> 11\u001b[0m         time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m         count \u001b[39m=\u001b[39m i\n\u001b[1;32m     13\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcount = \u001b[39m\u001b[39m\"\u001b[39m, count)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# without multi-threading\n",
    "import time\n",
    "\n",
    "complete = False\n",
    "count = 0\n",
    "inp_list = list(range(21))\n",
    "\n",
    "def worker(inp_list, count):\n",
    "    while not complete:\n",
    "        for i in inp_list:\n",
    "            time.sleep(1)\n",
    "            count = i\n",
    "            print(\"count = \", count)\n",
    "\n",
    "worker(inp_list, count)\n",
    "\n",
    "input(\"hit enter to exit loop\")\n",
    "complete = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604fce3b-93d5-476a-8955-6f8ed59b59ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  0\n",
      "count =  1\n",
      "count =  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  3\n"
     ]
    }
   ],
   "source": [
    "# to run both the input statement and worker function simultaneously \n",
    "\n",
    "import time\n",
    "import threading # importing threading module\n",
    "\n",
    "complete = False\n",
    "count = 0\n",
    "\n",
    "def worker(count):\n",
    "    while not complete:\n",
    "        time.sleep(1)\n",
    "        print(\"count = \", count)\n",
    "        count = count + 1 \n",
    "\n",
    "t1 = threading.Thread(target=worker, args=(count,)) # creating a thread called t1 using .Thread()\n",
    "t1.start() # starting the thead\n",
    "\n",
    "input(\"hit enter to exit loop\\n\")\n",
    "complete = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed00091",
   "metadata": {},
   "source": [
    "For certain algorithms, multi-threading can be more efficient than multi-processing.\n",
    "* Use Multithreading for tasks that relies on the input from another part of the system, or from the user\n",
    "* Use Multiprocessing for CPU intensive tasks (if you have multiple cores available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375bc11-8f3c-4809-a121-4d0c4171b9c4",
   "metadata": {},
   "source": [
    "# __Multiprocessing (Distributed-memory parallelism)__\n",
    "It is the ability of a system to support multiple more than one processor at the same time. Each process gets its own portion of your computer’s memory, ensuring that no process can interfere with the execution of another. (though Multiprocessing in python allows sharing of data between processes running locally)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a05b69-8e47-4ed1-bc12-8757dfdbbc2a",
   "metadata": {},
   "source": [
    "### Quick revision of processes ###\n",
    "Processes are-\n",
    "* Independent\n",
    "* Don't share memory\n",
    "* Run of different Processors, if available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810305f-9d3f-4b0c-b892-d8262ddf111e",
   "metadata": {},
   "source": [
    "### Overhead ###\n",
    "* started a new process requires overhead (The code gets replicated every time a new process is spun)\n",
    "* Hence, Use multiprocessing for job that more than a few seconds to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46174f7b-d521-4b08-a5d1-109baf3f04aa",
   "metadata": {},
   "source": [
    "# 'Process' class:  \n",
    "*  individual process that can run independently from the main process\n",
    "* The simplest way to spawn a second is to instantiate a Process object with a target function and call start() to let it begin working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de321fb-b2e6-47de-9bfe-50160633fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standup(updates, no_of_members):\n",
    "    \"\"\"\n",
    "    simulates a stand-up meeting by iterating over the range of `no_of_members` \n",
    "    and printing `updates` by introducing a 1-second delay between each update\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(no_of_members):\n",
    "        print(updates, i)\n",
    "        time.sleep(1)\n",
    "\n",
    "def work(task, no_of_tasks):\n",
    "    \"\"\"\n",
    "    simulates a work task by iterating over the range of `no_of_tasks` \n",
    "    and printing `task` by introducing a 1.5-second delay between execution of each task\n",
    "    \"\"\"\n",
    "    for i in range(no_of_tasks):\n",
    "        print(task, i)\n",
    "        time.sleep(1.5)\n",
    "\n",
    "def coffee():\n",
    "    \"\"\"\n",
    "    simulates a coffee break of 3 seconds\n",
    "    \"\"\"\n",
    "    time.sleep(10)\n",
    "    print(\"coffee break is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0dcf23-3558-4838-97d7-ddafa7702275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The update is being given by attendee no.  0\n",
      "The update is being given by attendee no.  1\n",
      "The update is being given by attendee no.  2\n",
      "The update is being given by attendee no.  3\n",
      "Task being completed is at priority  0\n",
      "Task being completed is at priority  1\n",
      "Task being completed is at priority  2\n",
      "coffee break is done\n",
      "It's time to go home\n",
      "time required =  18.527772903442383\n"
     ]
    }
   ],
   "source": [
    "# This code sequentially runs all the fuctions and does not make use of multiprocessing\n",
    "import time\n",
    "\n",
    "updates = \"The update is being given by attendee no. \"\n",
    "task = \"Task being completed is at priority \"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "standup(updates, 4)\n",
    "work(task, 3)\n",
    "coffee()\n",
    "\n",
    "print(\"It's time to go home\")\n",
    "print(\"time required = \", time.time() - start_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b804b01-770e-4110-8f8a-8aa67a7dec2f",
   "metadata": {},
   "source": [
    "* Args should be passed using a list or tuple to Process.\n",
    "\n",
    "eg: ```p = Process(target=print, args=[1])``` or\n",
    "```p = Process(target=print, args=(1,))```\n",
    "* Target should be passed as an object and not as function. Do not include parentheses\n",
    "\n",
    "eg: ```p = Process(target=print)``` and not ```p = Process(target=print())```\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d959e86-3545-47cd-87fc-427b8f7e84d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task being completed is at priority  0\n",
      "The update is being given by attendee no.  0\n",
      "The update is being given by attendee no.  1\n",
      "Task being completed is at priority  1\n",
      "The update is being given by attendee no.  2\n",
      "Task being completed is at priority  2\n",
      "The update is being given by attendee no.  3\n",
      "coffee break is done\n",
      "It's time to go home\n",
      "time required =  10.23836898803711\n"
     ]
    }
   ],
   "source": [
    "# Speeding up the code using multiprocessing\n",
    "import time\n",
    "import multiprocessing\n",
    "from with_multiprocessing import standup, work, coffee\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    updates = \"The update is being given by attendee no. \"\n",
    "    task = \"Task being completed is at priority \"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # spawning up individual \n",
    "    t1 = multiprocessing.Process(target=standup,args=(updates, 4))\n",
    "    t2 = multiprocessing.Process(target=work,args=(task, 3))\n",
    "    t3 = multiprocessing.Process(target=coffee)\n",
    "\n",
    "    # starting the processes\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    "\n",
    "    # wait until process 1 is finished\n",
    "    t1.join()\n",
    "    # wait until process 2 is finished\n",
    "    t2.join()\n",
    "    # wait until process 3 is finished\n",
    "    t3.join()\n",
    "\n",
    "    print(\"It's time to go home\")\n",
    "    print(\"time required = \", time.time() - start_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec68c5-adec-49a4-abbd-4f5a9eaf5d32",
   "metadata": {},
   "source": [
    "One difference between the __threading__ and __multiprocessing__ examples is the extra protection for ```__main__``` used in the multiprocessing examples. Due to the way the new processes are started, the child process needs to be able to import the script containing the target function. Wrapping the main part of the application in a check for ```__main__``` ensures that it is not run recursively in each child as the module is imported. Another approach is to import the target function from a separate script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c47c0-b8a2-489a-8ce7-4144e83556ab",
   "metadata": {},
   "source": [
    "# 'Pool' Class\n",
    "The __Pool__ class represents a pool of worker processes. \n",
    "```multiprocessing.pool``` provides a simple and convenient interface for parallel processing. It allows you to create a pool of worker processes, which can execute functions concurrently to achieve parallelism and speed up the execution of tasks. \n",
    "\n",
    "__pool is responsible for a fixed number of processes.__\n",
    "\n",
    "# Multiprocessing and Map Reduce\n",
    "The multiprocessing.Pool provides an excellent mechanism for the parallelisation of map/reduce style calculations. \n",
    "* Simple Map/Reduce: In a MapReduce-based system, input data is broken down into chunks for processing by different worker instances. Each chunk of input data is _mapped_ to an intermediate state using a simple transformation. The intermediate data is then collected together and partitioned based on a key value so that all of the related values are together. Finally, the partitioned data is reduced to a result set.\n",
    "\n",
    "NOTE:  the multiprocessing.pool module provides a reduce function, but it works a bit differently from the \"reduce\" step in MapReduce. The reduce function in multiprocessing.pool is used to perform a reduction operation on the elements of an iterable using a specified function, but it does not handle distributed data grouping as in the MapReduce paradigm.\n",
    "\n",
    "Let's look at asimple program to understand this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "375983d3-6903-47f2-b470-48bf1cfbf1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of squares =  [1, 4, 9, 16, 25]\n",
      "time required = 0.0007059574127197266\n"
     ]
    }
   ],
   "source": [
    "# This Code will execute sequentially making use of only 1 core\n",
    "import time\n",
    "\n",
    "def calc_square(i):\n",
    "   \"\"\"\n",
    "    returns the square of the the input value\n",
    "   \"\"\"\n",
    "   return i ** 2\n",
    "    \n",
    "list_of_nums = [1, 2, 3, 4, 5]\n",
    "result_list = []\n",
    "\n",
    "t1 = time.time()\n",
    "for i in list_of_nums:\n",
    "   result_list.append(calc_square(i))\n",
    "\n",
    "print(\"The list of squares = \", result_list)\n",
    "print(\"time required =\", time.time() - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652eb8f",
   "metadata": {},
   "source": [
    "![image info](images/without_map_reduce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18df1d-bb21-4c14-8121-8bba9717e035",
   "metadata": {},
   "source": [
    "Using the Pool class we can parallelize our work and map the inputs to the different cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c558ae",
   "metadata": {},
   "source": [
    "![image info](images/with_map_reduce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9bc80d-d105-45f1-9e68-8089a730ef2d",
   "metadata": {},
   "source": [
    "### After creating the process pool by calling a Multiprocessing.Pool object we submit tasks\n",
    "\n",
    "There are two main approaches for submitting tasks to the process pool, they are:\n",
    "\n",
    "1. __Issue tasks synchronously__:\n",
    "   Issuing tasks synchronously means that the caller will block until the issued task or tasks have completed.\n",
    "   Blocking calls to the process pool include map(), and starmap(), apply()\n",
    "   \n",
    "2. __Issue tasks asynchronously__:\n",
    "   Issuing tasks asynchronously to the process pool means that the caller will not block, allowing the caller to continue on with other work while the tasks are executing\n",
    "   Non-blocking calls to the process pool include apply_async(), map_async(), and starmap_async()\n",
    "\n",
    "   Lets look at synchronous calls first..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655b791-d0a9-4cb6-b94e-cf63ce6d1180",
   "metadata": {},
   "source": [
    "### __1. Synchronous Calls__\n",
    "# 1.a Apply()\n",
    "```apply(func[, args[, kwds]])```\n",
    "* ```apply()``` is used to issues a single task to the process pool.\n",
    "* It blocks the program until the function completes execution, which may be useful for certain synchronization requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8122d182-0136-471f-9ecb-88ae8c35091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_file_apply(file, string):\n",
    "    \"\"\"\n",
    "    creates and saves a single file with the given filename and content string\n",
    "    \"\"\"\n",
    "    file_name = f\"file_{file}.txt\"\n",
    "    time.sleep(2)        \n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(string)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1227d45f-3611-486f-ba9d-1c9b801ba893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_empid_27468.txt created\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "from apply import create_and_save_file_apply\n",
    " \n",
    "# protect the entry point\n",
    "if __name__ == '__main__':\n",
    "    # create and configure the process pool\n",
    "    pool = Pool()\n",
    "    # issue tasks to the process pool\n",
    "    result = pool.apply(create_and_save_file_apply, args=(\"empid_27468\", \"Falguni\"))\n",
    "    # report value\n",
    "    print(result, \"created\")\n",
    "    # close the process pool\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d4579-8561-4559-aa67-567e9a0cd82e",
   "metadata": {},
   "source": [
    "# 1. b Map()\n",
    "``` (func, iterable[, chunksize]) ```\n",
    "* map() is used to apply a function to multiple input elements concurrently.\n",
    "* It takes three arguments:\n",
    "  1. the function to be executed\n",
    "  2. an iterable (eg: like a list or tuple) containing multiple input arguments for that function.\n",
    "  3. (Optional) Chunksize\n",
    "* It is suitable when you want to process a batch of data and receive the results as a list in the same order as the input elements.\n",
    "The function is executed on each input element in parallel, and the return values are collected and returned as a list of results in the same order as the input elements.\n",
    "\n",
    "Let us look at a scenario where we aren't implementing pool.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309b29e1-5f41-4d6f-8ea8-ef7c28b1a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_files(string_array):\n",
    "    \"\"\"creates and saves files with the given input content string from string_array\"\"\"\n",
    "    for i, string in enumerate(string_array):\n",
    "        file_name = f\"file_{i+1}.txt\"\n",
    "        time.sleep(2)\n",
    "        with open(file_name, \"w\") as file:\n",
    "            file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c97a02d5-4834-4cc1-8457-ad9b38707429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time required =  18.030400037765503\n"
     ]
    }
   ],
   "source": [
    "# performs the file creation and writing operations sequentially, one after the other\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Array of 10 strings\n",
    "    strings = [\n",
    "        \"Abhijit\",\n",
    "        \"Anas\",\n",
    "        \"Ayush\",\n",
    "        \"Falguni\",\n",
    "        \"Harjot\",\n",
    "        \"Jigyasa\",\n",
    "        \"Prachi\"\n",
    "        \"Saurabh\",\n",
    "        \"Sheshant\",\n",
    "        \"Rahul\"]\n",
    "    start_time = time.time()\n",
    "    create_and_save_files(strings)\n",
    "    print(\"time required = \", time.time() - start_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa371d-341c-4cb0-baeb-31fc95414fed",
   "metadata": {},
   "source": [
    " If the list of strings is large and the file operations take considerable time, this sequential approach may not be the most efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc8e003e-206d-4513-a558-18ccf329bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_file_map(string_info):\n",
    "    i, string = string_info\n",
    "    file_name = f\"file_{i+10}.txt\"\n",
    "    time.sleep(2)\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(string)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaf9be7f-5fe5-40af-b10c-d737468f1307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file file_10.txt created\n",
      "file file_11.txt created\n",
      "file file_12.txt created\n",
      "file file_13.txt created\n",
      "file file_14.txt created\n",
      "file file_15.txt created\n",
      "file file_16.txt created\n",
      "file file_17.txt created\n",
      "file file_18.txt created\n",
      "file file_19.txt created\n",
      "time required = 2.5065529346466064\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pool_map import create_and_save_file_map\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    strings = [\n",
    "        \"Abhijit\",\n",
    "        \"Anas\",\n",
    "        \"Ayush\",\n",
    "        \"Falguni\",\n",
    "        \"Harjot\",\n",
    "        \"Jigyasa\",\n",
    "        \"Prachi\",\n",
    "        \"Saurabh\",\n",
    "        \"Sheshant\",\n",
    "        \"Rahul\"\n",
    "    ]\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    # Using multiprocessing pool with worker processes = the number of core available on the os\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        for item in pool.map(create_and_save_file_map, enumerate(strings)):\n",
    "            print(f\"file {item} created\")\n",
    "\n",
    "    pool.close()\n",
    "\n",
    "    print(\"time required =\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672e622-1bac-4799-a438-bf84e6331616",
   "metadata": {},
   "source": [
    "### the Pool.map() function only takes one iterable as an argument. This means that the target function executed in the process can only take a single argument. However, if we want multiple iterators as an input, we can use starmap()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3286a1-b7fb-48a4-b31f-6f7c707e0368",
   "metadata": {},
   "source": [
    "# 1.c Starmap()\n",
    "```(func, iterable[, chunksize])```\n",
    "* starmap() is used to issue multiple tasks to the process pool.\n",
    "* It takes 3 arguments:\n",
    "  1. The function to be executed\n",
    "  2. An iterable of tuples\n",
    "     eg. ```[(1,2), (3, 4)]``` results in ```[func(1,2), func(3,4)]```.\n",
    "  4. (Optional)  Chunksize\n",
    " * starmap() treats each element of the iterable as a separate set of arguments to the function.\n",
    " * If your function can handle multiple arguments or if you need to pass multiple pieces of data to the function for each element, then starmap() is the better choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a387306-3fd2-42a7-bd78-7430c486e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_file_starmap(string_info, time_out):\n",
    "    i, string = string_info\n",
    "    file_name = f\"file_{i+20}.txt\"\n",
    "    time.sleep(time_out)\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(string)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8a5078-c4d6-4db1-8117-874af5651c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 'Abhijit'), 1), ((1, 'Anas'), 2), ((2, 'Ayush'), 3), ((3, 'Falguni'), 1), ((4, 'Harjot'), 2), ((5, 'Jigyasa'), 3), ((6, 'Prachi'), 1), ((7, 'Saurabh'), 2), ((8, 'Sheshant'), 3), ((9, 'Rahul'), 2)]\n",
      "file file_20.txt created\n",
      "file file_21.txt created\n",
      "file file_22.txt created\n",
      "file file_23.txt created\n",
      "file file_24.txt created\n",
      "file file_25.txt created\n",
      "file file_26.txt created\n",
      "file file_27.txt created\n",
      "file file_28.txt created\n",
      "file file_29.txt created\n",
      "time required = 3.4832839965820312\n"
     ]
    }
   ],
   "source": [
    "# in this code along with the string we also want one of the arguments to be the individual time_outs\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pool_starmap import create_and_save_file_starmap\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    strings = [\n",
    "        \"Abhijit\",\n",
    "        \"Anas\",\n",
    "        \"Ayush\",\n",
    "        \"Falguni\",\n",
    "        \"Harjot\",\n",
    "        \"Jigyasa\",\n",
    "        \"Prachi\",\n",
    "        \"Saurabh\",\n",
    "        \"Sheshant\",\n",
    "        \"Rahul\"\n",
    "    ]\n",
    "    time_out = [1, 2, 3, 1, 2, 3, 1, 2, 3, 2]\n",
    "    start_time = time.time()\n",
    "\n",
    "    # prepare arguments\n",
    "    input_tuples = list(zip(enumerate(strings), time_out))\n",
    "\n",
    "    print(input_tuples)\n",
    "    \n",
    "    # Using multiprocessing pool with worker processes = the number of core available on the os\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        for item in pool.starmap(create_and_save_file_starmap, input_tuples):\n",
    "            print(f\"file {item} created\")\n",
    "\n",
    "    pool.close()\n",
    "\n",
    "    print(\"time required =\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c28900a-c9ee-4105-a60e-6b470e5686b8",
   "metadata": {},
   "source": [
    "### Chunksize\n",
    "* In both map() and starmap() it is possible to split up the items in the iterable evenly to worker processes.\n",
    "For example, if we had a process pool with 4 processes and an iterable with 40 items, we can split up the items into 4 chunks of 10 items, with one chunk allocated to each worker process.\n",
    "``` pool.map(task, items, chunksize=10) ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d962b0-4ef8-49ed-87c4-d99c6ebb74f5",
   "metadata": {},
   "source": [
    "__Importantly, it is important to note that in all create_and_save_file(), the function calls are issued and executed before the iterator of results is returned__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9906da7-a774-469b-b352-5c9d4e2784d3",
   "metadata": {},
   "source": [
    "### 2. __Asynchronous Calls__\n",
    "\n",
    "\n",
    "\n",
    "# 2.a Apply_async()\n",
    "```(func[, args[, kwds[, callback[, error_callback]]]])```\n",
    "\n",
    "* The apply_async() function is an asynchronous method used to execute a function on a single input argument at a time, __but it does not block the program's execution__.\n",
    "* Instead of waiting for the result, it __returns an AsyncResult__ object immediately, representing the result of the function call (which might not be ready yet).\n",
    "* You can later use the ```get()``` method on the AsyncResult object to __retrieve the result__, which will block the program's execution until the result is available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df5ccf-d72f-4951-aee7-d7242f5e5e5a",
   "metadata": {},
   "source": [
    "### .get()\n",
    "We can later use the ```get()``` method on the AsyncResult object to retrieve the results, and this call can block the program's execution until all the results are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d45f2dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_empid_27468.txt created\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "from apply import create_and_save_file_apply\n",
    "\n",
    "# protect the entry point\n",
    "if __name__ == '__main__':\n",
    "    # create and configure the process pool\n",
    "    pool = Pool()\n",
    "    # issue tasks to the process pool\n",
    "    result = pool.apply_async(create_and_save_file_apply, args=(\"empid_27468\", \"Falguni\"))\n",
    "    # report value\n",
    "    print(result.get(), \"created\")\n",
    "    # close the process pool\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20039687-4cff-4d18-a612-c7c96d4ea391",
   "metadata": {},
   "source": [
    "# 2.b Map_async()\n",
    "```(func, iterable[, chunksize[, callback[, error_callback]]])```\n",
    "* The map_async() function is a non-blocking method that applies the specified function to each element of the input iterable in parallel.\n",
    "* Return values are collected asynchronously using an __AsyncResult object__.\n",
    "* The map_async() call returns immediately, allowing the program to continue executing other tasks without waiting for the results.\n",
    "\n",
    "map_async() is more efficient in dealing with slow-running processes and it can be useful when you have other tasks to perform while waiting for the function calls to complete. Overall program efficiency and responsiveness could be improved using this.\n",
    "\n",
    "_NOTE_: it's essential to manage the AsyncResult objects correctly to avoid potential issues like race conditions or excessive resource consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "499dcf8d-2860-425b-b3bd-62a2249af673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other work while waiting for function calls to complete...\n",
      "file file_30.txt created\n",
      "file file_31.txt created\n",
      "file file_32.txt created\n",
      "file file_33.txt created\n",
      "file file_34.txt created\n",
      "file file_35.txt created\n",
      "file file_36.txt created\n",
      "file file_37.txt created\n",
      "file file_38.txt created\n",
      "file file_39.txt created\n",
      "Time required = 2.5167250633239746\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pool_map_async import create_and_save_file_map\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    strings = [\n",
    "        \"Abhijit\",\n",
    "        \"Anas\",\n",
    "        \"Ayush\",\n",
    "        \"Falguni\",\n",
    "        \"Harjot\",\n",
    "        \"Jigyasa\",\n",
    "        \"Prachi\",\n",
    "        \"Saurabh\",\n",
    "        \"Sheshant\",\n",
    "        \"Rahul\"\n",
    "    ]\n",
    "    start_time = time.time()\n",
    "\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        result_async = pool.map_async(create_and_save_file_map, enumerate(strings))\n",
    "        print(\"Other work while waiting for functions to complete...\")\n",
    "\n",
    "        # blocking call using .get()\n",
    "        results = result_async.get()\n",
    "\n",
    "        for item in results:\n",
    "            print(f\"file {item} created\")\n",
    "\n",
    "    print(\"Time required =\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf1001-2b53-440c-b440-c73a001a6046",
   "metadata": {},
   "source": [
    "# 2.c Starmap_async()\n",
    "\n",
    "```(func, iterable[, chunksize[, callback[, error_callback]]])```\n",
    "* ```starmap_async()``` combination of ```starmap()``` and ```map_async()``` that iterates over iterable of iterables.\n",
    "* when called unpacks the iterables and returns an AsyncResult object.\n",
    "  Similar to map_async(), starmap_async() it can be useful when you have other tasks to perform while waiting for the function calls to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03641a4a-e87d-4f35-83d2-a4629aaa929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 'Abhijit'), 1), ((1, 'Anas'), 2), ((2, 'Ayush'), 3), ((3, 'Falguni'), 1), ((4, 'Harjot'), 2), ((5, 'Jigyasa'), 3), ((6, 'Prachi'), 1), ((7, 'Saurabh'), 2), ((8, 'Sheshant'), 3), ((9, 'Rahul'), 2)]\n",
      "Other work while waiting for function calls to complete...\n",
      "file file_40.txt created\n",
      "file file_41.txt created\n",
      "file file_42.txt created\n",
      "file file_43.txt created\n",
      "file file_44.txt created\n",
      "file file_45.txt created\n",
      "file file_46.txt created\n",
      "file file_47.txt created\n",
      "file file_48.txt created\n",
      "file file_49.txt created\n",
      "time required = 3.5598671436309814\n"
     ]
    }
   ],
   "source": [
    "from pool_starmap_async import create_and_save_file_starmap\n",
    "import time\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    strings = [\n",
    "        \"Abhijit\",\n",
    "        \"Anas\",\n",
    "        \"Ayush\",\n",
    "        \"Falguni\",\n",
    "        \"Harjot\",\n",
    "        \"Jigyasa\",\n",
    "        \"Prachi\",\n",
    "        \"Saurabh\",\n",
    "        \"Sheshant\",\n",
    "        \"Rahul\"\n",
    "    ]\n",
    "    start_time = time.time()\n",
    "\n",
    "    time_out = [1, 2, 3, 1, 2, 3, 1, 2, 3, 2]\n",
    "    start_time = time.time()\n",
    "\n",
    "    # prepare arguments\n",
    "    input_tuples = list(zip(enumerate(strings), time_out))\n",
    "\n",
    "    print(input_tuples)\n",
    "    \n",
    "    # Using multiprocessing pool with worker processes = the number of core available on the os\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        # Use map_async instead of map\n",
    "        result_async = pool.starmap_async(create_and_save_file_starmap, input_tuples)\n",
    "        print(\"Other work while waiting for functions to complete...\")\n",
    "\n",
    "        # blocking call using get()\n",
    "        results = result_async.get()\n",
    "\n",
    "        for item in results:\n",
    "            print(f\"file {item} created\")\n",
    "\n",
    "    pool.close()\n",
    "\n",
    "    print(\"time required =\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cf770-9254-4bfd-8c96-6704d861e39c",
   "metadata": {},
   "source": [
    "## Callback\n",
    "We can send tasks to the process pool, and for each task's returned value, we can specify a callback function to handle and process that value using a callback function\n",
    "\n",
    "Example usage (not to be run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d20e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task():\n",
    "    return \"done\"\n",
    "\n",
    "def custom_callback(result):\n",
    "    print(f'Callback got values: {result}')\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        _ = pool.map_async(create_and_save_file_map, enumerate(strings), callback=custom_callback)\n",
    "        pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad370b3-ab0f-40cf-993d-f83fcb395425",
   "metadata": {},
   "source": [
    "# 3.a imap()\n",
    "\n",
    "```(func, iterable[, chunksize])```\n",
    "* Lazy map()\n",
    "* We can issue tasks to the process pool one-by-one via the imap() function.\n",
    "* Returns an iterator that yields the results as they become available.\n",
    "\n",
    "* __Difference between imap() and map()__: map() returns a list containing all results, while imap() returns an iterator that yields results as they are computed\n",
    "* __Difference between imap() and map_async()__: imap() and map_async() both are non-blocking calls. However, \n",
    "while imap() returns an iterator that yields results lazily, map_async() returns an AsyncResult object immediately, and you can retrieve the results later using get(). map_async() still collects all results in memory, but it doesn't block the program while waiting for results, allowing you to perform other tasks.\n",
    "* __imap() is useful over map() when you want to process large datasets efficiently and avoid high memory usage__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e41fe-4fd9-4547-83b6-f554b95eb55d",
   "metadata": {},
   "source": [
    "# 3.b imap_unordered\n",
    "```(func, iterable[, chunksize])```\n",
    "* The __same as imap()__ except that the ordering of the results.\n",
    "* The iterable will yield return values as tasks are completed, in the order that tasks were completed, not the order they were issued\n",
    "* Hence, order of the results could be arbitrary\n",
    "\n",
    "__Use imap_unordered() when you have a large dataset and the processing order is not critical.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e45f2",
   "metadata": {},
   "source": [
    "# Progess Bar\n",
    "We can add a progress bar using ```tqdm``` to monitor the execution of processes within a pool in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592819d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from progress_bar import slow_square\n",
    "\n",
    "def slow_square(number):\n",
    "    # Simulate a computationally inefficient task by adding a delay\n",
    "    time.sleep(1)\n",
    "    return number ** 2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numbers = range(100)\n",
    "    results = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(numbers), desc='Processing')\n",
    "\n",
    "    with Pool() as pool:\n",
    "        for item in pool.imap(slow_square, numbers):\n",
    "            results.append(item)\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    print(\"Results with multiprocessing:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffc1c3",
   "metadata": {},
   "source": [
    "### In multiprocessing, any newly created process will do following:\n",
    "* run independently\n",
    "* have their own memory space.\n",
    "the map() function in the multiprocessing.pool module does not directly support process-to-process communication during mapping.\n",
    "However, The multiprocessing module in Python provides mechanisms for inter-process communication (IPC) to enable communication between different processes\n",
    "\n",
    "Two of the most popular methods are:\n",
    "1. Pipes (for a connection between two processes)\n",
    "2. Queues (which allows multiple producers and consumers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3ff44",
   "metadata": {},
   "source": [
    "# 1. Pipe\n",
    "```multiprocessing.Pipe([duplex])```\n",
    "\n",
    "* Enables inter-process communication (IPC) between two processes.\n",
    "* Allows two processes to communicate by creating a unidirectional connection.\n",
    "* One end of the pipe is used for sending data, and the other end is used for receiving data.\n",
    "* Exchange data sequentially.\n",
    "* One process acts as the sender, writing data into the pipe, while the other process acts as the receiver, reading the data from the pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "718337a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(conn):\n",
    "    message = \"Hello, team!\"\n",
    "\n",
    "    conn.send(message)  # Sending message through the pipe\n",
    "    print(f\"Sent: {message}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "def receive_message(conn):\n",
    "    message = conn.recv()  # Receiving message from the pipe\n",
    "    print(f\"Received: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccfc3e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: Hello, team!\n",
      "Received: Hello, team!\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from pipe import send_message, receive_message\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a pipe\n",
    "    parent_conn, child_conn = multiprocessing.Pipe()\n",
    "\n",
    "    # Create two processes: one for sending messages and one for receiving messages\n",
    "    sender_process = multiprocessing.Process(target=send_message, args=(parent_conn,))\n",
    "    receiver_process = multiprocessing.Process(target=receive_message, args=(child_conn,))\n",
    "\n",
    "    sender_process.start()\n",
    "    receiver_process.start()\n",
    "\n",
    "    sender_process.join()\n",
    "    receiver_process.join()\n",
    "\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b8310",
   "metadata": {},
   "source": [
    "* The ```Connection.send()``` function can be used to send objects from one process to another.\n",
    "* The ```Connection.recv()``` function can be used to receive objects in one process sent by another.\n",
    "* When we call multiprocessing.Pipe() it returns a tupple eg (conn1, conn2). conn1 can only send data and conn2 can only be used to recieve data.\n",
    "\n",
    "  However, A multiprocessing.Pipe can be used to both send and receive data between two processes.\n",
    "  This is called a duplex and can be achieved by setting the __“duplex”__ argument to True when creating a pipe\n",
    "  example: ``` parent_conn, child_conn = multiprocessing.Pipe(duplex=True)```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
